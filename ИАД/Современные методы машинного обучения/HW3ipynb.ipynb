{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORgUNkSW5Ml5"
   },
   "source": [
    "# –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ 3. \n",
    "\n",
    "## –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏ –æ—Ç–µ–ª—è –ø–æ —Ç–µ–∫—Å—Ç—É –æ—Ç–∑—ã–≤–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aat77DoZ5OGy"
   },
   "source": [
    "–ú—ã —Å–æ–±—Ä–∞–ª–∏ –¥–ª—è –≤–∞—Å –æ—Ç–∑—ã–≤—ã –ø–æ 1500 –æ—Ç–µ–ª—è–º –∏–∑ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ —Ä–∞–∑–Ω—ã—Ö —É–≥–æ–ª–∫–æ–≤ –º–∏—Ä–∞. –ß—Ç–æ —ç—Ç–æ –∑–∞ –æ—Ç–µ–ª–∏ - —Å–µ–∫—Ä–µ—Ç. –í–∞–º –¥–∞–Ω —Ç–µ–∫—Å—Ç –æ—Ç–∑—ã–≤–∞ –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –æ—Ç–µ–ª—è. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –Ω–∞—É—á–∏—Ç—å—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –æ—Ü–µ–Ω–∫—É –æ—Ç–µ–ª—è –ø–æ –æ—Ç–∑—ã–≤—É. –î–∞–Ω–Ω—ã–µ –º–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å [—Ç—É—Ç](https://www.kaggle.com/c/hseds-texts-2020/data?select=train.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_pFZFG75R7z"
   },
   "source": [
    "–î–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ train –∏ test –∏ –∑–∞–º–µ—Ä—è–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π —á–∞—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERN1KCC85Uev"
   },
   "source": [
    "#### –ü—Ä–æ –¥–∞–Ω–Ω—ã–µ:\n",
    "–ö–∞–∂–¥–æ–µ —Ä–µ–≤—å—é —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–≤—É—Ö —Ç–µ–∫—Å—Ç–æ–≤: positive –∏ negative - –ø–ª—é—Å—ã –∏ –º–∏–Ω—É—Å—ã –æ—Ç–µ–ª—è. –í —Å—Ç–æ–ª–±—Ü–µ score –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –æ—Ü–µ–Ω–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - –≤–µ—â–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —á–∏—Å–ª–æ 0 –¥–æ 10. –í–∞–º –Ω—É–∂–Ω–æ –∏–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —ç—Ç–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –ø–æ –Ω–∏–º –æ—Ü–µ–Ω–∫—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qG5MdkJe5XFF"
   },
   "source": [
    "–£–¥–∞—á–∏! üí™"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-qqFLuN5Z2x"
   },
   "source": [
    "#### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–Ω–µ—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å—Ç—Ä–æ–≥–æ –∑–∞–ø—Ä–µ—â–µ–Ω–æ. –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WzacMIHa5iyS"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4HqeRfvoKhDH",
    "outputId": "6993b556-727f-416a-e202-c88d4b732d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7lgRHsnbKjg5",
    "outputId": "96c2613a-386b-416b-b01a-1aae78b1572a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uBVjAdPI_gd2"
   },
   "outputs": [],
   "source": [
    "!unzip /content/drive/MyDrive/hseds-texts-2020.zip > /dev/null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dryuDLV1_rah"
   },
   "outputs": [],
   "source": [
    "PATH_TO_TRAIN_DATA = 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "ZLiiuq1AARud",
    "outputId": "e3a1c14b-800f-4c19-eb44-8334942197ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003c6036f30f590c0ac435efb8739b</td>\n",
       "      <td>There were issues with the wifi connection</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004d18f186bf2489590dc415876f73</td>\n",
       "      <td>TV not working</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000cf900cbb8667fad33a717e9b1cf4</td>\n",
       "      <td>More pillows</td>\n",
       "      <td>Beautiful room Great location Lovely staff</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000df16edf19e7ad9dd8c5cd6f6925e</td>\n",
       "      <td>Very business</td>\n",
       "      <td>Location</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00025e1aa3ac32edb496db49e76bbd00</td>\n",
       "      <td>Rooms could do with a bit of a refurbishment ...</td>\n",
       "      <td>Nice breakfast handy for Victoria train stati...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id  ... score\n",
       "0  00003c6036f30f590c0ac435efb8739b  ...   7.1\n",
       "1  00004d18f186bf2489590dc415876f73  ...   7.5\n",
       "2  0000cf900cbb8667fad33a717e9b1cf4  ...  10.0\n",
       "3  0000df16edf19e7ad9dd8c5cd6f6925e  ...   5.4\n",
       "4  00025e1aa3ac32edb496db49e76bbd00  ...   6.7\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "df = pd.read_csv(PATH_TO_TRAIN_DATA)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jF9LCP4ZMqUi"
   },
   "source": [
    "–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –º–æ–∂–µ—Ç —Å–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏.\n",
    "–°–¥–µ–ª–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–æ–≤: —É–¥–∞–ª–∏–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –ø—Ä–∏–≤–µ–¥–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É. \n",
    "–û–¥–Ω–∞–∫–æ –º–æ–∂–Ω–æ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å—Å—è —ç—Ç–∏–º –Ω–∞–±–æ—Ä–æ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π. –ü–æ–¥—É–º–∞–π—Ç–µ, —á—Ç–æ –µ—â–µ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Å —Ç–µ–∫—Å—Ç–∞–º–∏, —á—Ç–æ–±—ã –ø–æ–º–æ—á—å –±—É–¥—É—â–∏–º –º–æ–¥–µ–ª—è–º? –î–æ–±–∞–≤—å—Ç–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥–ª–∏ –±—ã –ø–æ–º–æ—á—å –ø–æ –≤–∞—à–µ–º—É –º–Ω–µ–Ω–∏—é."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJS4LQ-_Ms34"
   },
   "source": [
    "–¢–∞–∫–∂–µ –º—ã –¥–æ–±–∞–≤–∏–ª–∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ —Ç–æ–∫–µ–Ω—ã. –¢–µ–ø–µ—Ä—å –∫–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞-—Ä–µ–≤—å—é —Å—Ç–∞–ª–∞ –º–∞—Å—Å–∏–≤–æ–º —Ç–æ–∫–µ–Ω–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pv5FzFP0MwON"
   },
   "source": [
    "### –ß–∞—Å—Ç—å 1. 1 –±–∞–ª–ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oB4zXmLKu9ju"
   },
   "source": [
    "–°–Ω–∞—á–∞–ª–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—Ä—É–µ–º –∏ –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä—É–µ–º, —É–±–µ—Ä–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –∏ —Ü–∏—Ñ—Ä—É"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "g01LYkMuS3eL"
   },
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "  wordnet_lemmatizer = WordNetLemmatizer()\n",
    "  return ' '.join([wordnet_lemmatizer.lemmatize(word) for word in word_tokenize(text.lower()) if word not in string.punctuation])\n",
    "\n",
    "def minus_digits(text):\n",
    "  return ' '.join([word for word in text.split(' ') if not any(map(str.isdigit, word))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kdwASIpmvQSF"
   },
   "outputs": [],
   "source": [
    "df['negative'] = df['negative'].apply(process_text)\n",
    "df['positive'] = df['positive'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cOmcqWdPvuOU"
   },
   "outputs": [],
   "source": [
    "df['negative'] = df['negative'].apply(minus_digits)\n",
    "df['positive'] = df['positive'].apply(minus_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DfRjqBnnvQDu"
   },
   "outputs": [],
   "source": [
    "df['final_preprocessing'] = df['negative'] + ' ' + df['positive'] #—Å–¥–µ–ª–∞–µ–º —Å—Ç–æ–ª–±–µ—Ü –≥–¥–µ –±—É–¥–µ–º —Ö—Ä–∞–Ω–∏—Ç—å –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∏ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –æ—Ç–∑—ã–≤—ã –≤–º–µ—Å—Ç–µ\n",
    "df_train, df_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zyGo1nJcMB21"
   },
   "outputs": [],
   "source": [
    "sklearn_pipeline = Pipeline((('vect', TfidfVectorizer()),\n",
    "                             ('cls', SGDRegressor())))\n",
    "sklearn_pipeline.fit(df_train['final_preprocessing'], df_train['score']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Yun0wnLMEY-",
    "outputId": "d25012c5-f587-4d68-f583-fde3895ffa8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9744102977331616"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(df_test['score'], sklearn_pipeline.predict(df_test['final_preprocessing']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7lvui39Ax3Ii"
   },
   "source": [
    "### –ß–∞—Å—Ç—å 3. 6 –±–∞–ª–ª–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qD-1mfQZUDSu"
   },
   "source": [
    "–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –±–æ–ª–µ–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –ø—Ä–æ—Ö–æ–¥–∏–ª–∏ –≤ –Ω–∞—à–µ–º –∫—É—Ä—Å–µ. –û–±—É—á–∏—Ç–µ RNN/Transformer –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏. –ü–æ–ª—É—á–∏—Ç–µ –æ—à–∏–±–∫—É –º–µ–Ω—å—à–µ, —á–µ–º –≤–æ –≤—Å–µ—Ö –≤—ã—à–µ–ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–∞—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nA0Q23lIUDI1"
   },
   "source": [
    "–ï—Å–ª–∏ –±—É–¥–µ—Ç–µ –æ–±—É—á–∞—Ç—å RNN, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–∑—ã–≤—ã –º–æ–≥—É—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö.\n",
    "\n",
    "–ß—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è DataLoader, –≤—Å–µ –µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏. –î–ª—è —ç—Ç–æ–≥–æ –≤—ã –º–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –Ω—É–ª–µ–≤–æ–π –ø–∞–¥–¥–∏–Ω–≥ –∫–æ –≤—Å–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º (—Å–º –ø—Ä–∏–º–µ—Ä pad_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmvtMhfTbYO-"
   },
   "source": [
    "–î–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π —Ä–∞–±–æ—Ç—ã –±—É–¥–µ–º –∏–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–π —Å–∞–π—Ç https://huggingface.co/transformers/model_doc/bert.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "s-SUcpczx4nO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3MCaSMkaX2MR",
    "outputId": "e0bf3d26-62c0-4095-977c-b2c9ba162fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
      "\r",
      "\u001b[K     |‚ñà‚ñâ                              | 10kB 24.1MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñä                            | 20kB 28.8MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 30kB 21.2MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 40kB 17.4MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 51kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                    | 61kB 13.7MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 71kB 13.5MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 81kB 13.5MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 92kB 13.2MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 102kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 112kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 122kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 133kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 143kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 153kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 163kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 174kB 13.1MB/s eta 0:00:01\r",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 184kB 13.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (4.41.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2019.12.20)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.7.0+cu101)\n",
      "Collecting boto3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/c1/5c2b2259dd4a149f873f1ab9b4c5ef106c828a4abc7230c9452be8c27493/boto3-1.16.41-py2.py3-none-any.whl (130kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 133kB 35.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.19.4)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 890kB 32.7MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.1MB 49.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch_transformers) (0.16.0)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch_transformers) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n",
      "Collecting botocore<1.20.0,>=1.19.41\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/69/eecc498592e2ee9a300037881b38637358dbddd5211d2af061c8b177abe4/botocore-1.19.41-py2.py3-none-any.whl (7.1MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.2MB 50.8MB/s \n",
      "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71kB 11.3MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.41->boto3->pytorch_transformers) (2.8.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=904b5faf5058158244bab1c7730c7c925e9dcd02a13853caa48abf260e7af461\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "\u001b[31mERROR: botocore 1.19.41 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, sacremoses, sentencepiece, pytorch-transformers\n",
      "Successfully installed boto3-1.16.41 botocore-1.19.41 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JBVkF7ZjXjn2"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from pytorch_transformers import BertTokenizer, BertConfig\n",
    "from pytorch_transformers import BertForSequenceClassification\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OYxuiPUFdLwl"
   },
   "outputs": [],
   "source": [
    "set_score = list(set(df.score.tolist()))\n",
    "dict_score = {set_score[item]:item for item in range(len(set_score))}\n",
    "def change(score):\n",
    "  return(dict_score[score['score']])\n",
    "  \n",
    "df['score_class'] = df.apply(change, axis=1)\n",
    "\n",
    "df_train, df_test = train_test_split(df)\n",
    "# —Å–æ–∑–¥–∞–¥–∏–º score_class –≤ –∫–æ—Ç–æ—Ä–æ–º –±—É–¥–µ–º —Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ score, –∏ –æ–ø—è—Ç—å —Ä–∞–∑–æ–±—ä–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –Ω–∞ test –∏ train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4FGYAkROXjg2"
   },
   "outputs": [],
   "source": [
    "# –ë–µ—Ä—Ç –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Ç–∏–ø '[CLS] hi [SEP]'\n",
    "sentences_train = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in df_train['final_preprocessing']]\n",
    "labels_train = [item for item in df_train['score_class'].tolist()]\n",
    "\n",
    "sentences_test = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in df_test['final_preprocessing']]\n",
    "labels_test = [item for item in df_test['score_class'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1INu5XjhaT4U",
    "outputId": "e5fc2c9f-d2ce-4aa4-db87-5417d5dcd19e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 231508/231508 [00:00<00:00, 36303695.01B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'honestly', 'nothing', 'it', 'wa', 'a', 'perfect', 'experience', 'very', 'professional', 'and', 'helpful', 'staff', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞–∑–æ–≤—ã–µ –ë–µ—Ä—Ç, –≥–¥–µ —Å–ª–æ–≤–∞ –∏–º–µ—é—Ç –Ω–∏–∂–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä\n",
    "\n",
    "tokenized_texts_train = [tokenizer.tokenize(sent) for sent in sentences_train]\n",
    "print (tokenized_texts_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkIQ9un7fkO1",
    "outputId": "8510a585-257d-471d-b427-ec0c01492931"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (547 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 200\n",
    "train_input = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_train]\n",
    "\n",
    "train_pos_pad = pad_sequence([torch.as_tensor(seq[:MAX_LEN]) for seq in train_input], \n",
    "                           batch_first=True)\n",
    "\n",
    "train_masks = [[float(i>0) for i in seq] for seq in train_pos_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3E5d3J5FnL87",
    "outputId": "8c4c7306-ace8-4d2e-e44a-df1bb4c32061"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts_test = [tokenizer.tokenize(sent) for sent in sentences_test]\n",
    "\n",
    "test_input = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_test]\n",
    "test_pos_pad = pad_sequence([torch.as_tensor(seq[:MAX_LEN]) for seq in test_input], \n",
    "                           batch_first=True)\n",
    "\n",
    "validation_masks = [[float(i>0) for i in seq] for seq in test_pos_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zp1TTcH6aTxM",
    "outputId": "09c7aaf4-24dd-41dd-84cf-a1e38f96391b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_inputs = torch.tensor(train_pos_pad)\n",
    "train_labels = torch.tensor(labels_train)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "\n",
    "\n",
    "validation_inputs = torch.tensor(test_pos_pad)\n",
    "validation_labels = torch.tensor(labels_test)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7g3O9-V_drPR"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, shuffle=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGLFeBu8eBCV",
    "outputId": "a23c0199-a168-44c8-ddf1-26b3ff2b0390"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 433/433 [00:00<00:00, 120369.41B/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 440473133/440473133 [00:05<00:00, 82307172.01B/s]\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=37)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "sLRv5F141XSa"
   },
   "outputs": [],
   "source": [
    "# —Ñ—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–∞ –≤ score\n",
    "dict_score_class = {item:set_score[item] for item in range(len(set_score))} #set_score = list(set(df.score.tolist())) (–ù–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ)\n",
    "def mae(pred, label):\n",
    "  pred =  [dict_score_class[item] for item in pred]\n",
    "  label = [dict_score_class[item] for item in label]\n",
    "  return mean_absolute_error(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "zI8O5i8LplzE"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, optimizer, device=\"cuda:0\"):\n",
    "    model.to(device).train()\n",
    "    with tqdm(total=len(train_dataloader)) as pbar:\n",
    "     for batch in train_dataloader:\n",
    "        # –¥–æ–±–∞–≤–ª—è–µ–º –±–∞—Ç—á –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ GPU\n",
    "        # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ dataloader\n",
    "        input_ids, input_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(input_ids, token_type_ids=None, attention_mask=input_mask, labels=labels)\n",
    "        loss[0].backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = loss[1].detach().cpu().numpy()\n",
    "       \n",
    "        batch_preds = np.argmax(predicted, axis=1)\n",
    "        accuracy_mae = mae(batch_preds, labels.cpu().numpy())\n",
    "        pbar.set_description('Loss: {:.4f}; Accuracy_MAE: {:.4f}'.format(loss[0].item(), accuracy_mae))    \n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "qdIqeA9Z0rCF",
    "outputId": "afe34dd6-3dd8-4d5c-81e4-b4803bb52b11"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1259; Accuracy_MAE: 1.0219:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2234/2344 [42:44<02:06,  1.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-cb429cbebc24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-cc97322f9ae5>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_one_epoch(model, train_dataloader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Le4FsO5ovuvk"
   },
   "outputs": [],
   "source": [
    "def predict(model, val_dataloader, device=\"cuda:0\"):\n",
    "    model.to(device).eval()\n",
    "    losses = []\n",
    "    predicted_classes = []\n",
    "    true_classes = []\n",
    "    valid_preds, valid_labels = [], []\n",
    "    with tqdm(total=len(val_dataloader)) as pbar:\n",
    "      with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "          # –¥–æ–±–∞–≤–ª—è–µ–º –±–∞—Ç—á –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ GPU\n",
    "          batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "          # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ dataloader\n",
    "          input_ids, input_mask, labels = batch\n",
    "          \n",
    "          logits = model(input_ids, token_type_ids=None, attention_mask=input_mask)\n",
    "          \n",
    "          logits = logits[0].detach().cpu().numpy()\n",
    "          label_ids = labels.to('cpu').numpy()\n",
    "          \n",
    "          \n",
    "          batch_preds = np.argmax(logits, axis=1)\n",
    "    \n",
    "          batch_labels = np.stack(label_ids)     \n",
    "          valid_preds.extend(batch_preds)\n",
    "          valid_labels.extend(batch_labels)\n",
    "\n",
    "          accuracy_mae = mae(batch_preds, label_ids)\n",
    "          pbar.set_description('Accuracy_MAE: {:.4f}'.format(accuracy_mae))\n",
    "          pbar.update(1)\n",
    "\n",
    "    return valid_preds, valid_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOuRiOxnLbQ4",
    "outputId": "0c2a47b3-32f9-4965-bc01-99dce6833b33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accuracy_MAE: 1.1375: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 782/782 [05:32<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.987692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_classes, true_classes = predict(model, validation_dataloader)\n",
    "print('MAE: ', mae(predicted_classes,true_classes ))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "HW3ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

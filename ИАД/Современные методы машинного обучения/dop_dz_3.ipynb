{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kOxSNy6k-ZWA"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32bTTrrY-lKo",
    "outputId": "c9ef9205-9639-474b-e69f-9447c79a9400"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgjvwwjO-mhB",
    "outputId": "75cc9c1c-8430-419e-8cef-9259153ed61f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Y4SqRE4T-oiO"
   },
   "outputs": [],
   "source": [
    "!unzip hseds-texts-2020.zip > /dev/null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "N3mdY-az-qO4"
   },
   "outputs": [],
   "source": [
    "PATH_TO_TRAIN_DATA = 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "YQGK3Gp6-r1z",
    "outputId": "657cc1e0-453c-4223-f6e6-62a70f56d98b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003c6036f30f590c0ac435efb8739b</td>\n",
       "      <td>There were issues with the wifi connection</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00004d18f186bf2489590dc415876f73</td>\n",
       "      <td>TV not working</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000cf900cbb8667fad33a717e9b1cf4</td>\n",
       "      <td>More pillows</td>\n",
       "      <td>Beautiful room Great location Lovely staff</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000df16edf19e7ad9dd8c5cd6f6925e</td>\n",
       "      <td>Very business</td>\n",
       "      <td>Location</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00025e1aa3ac32edb496db49e76bbd00</td>\n",
       "      <td>Rooms could do with a bit of a refurbishment ...</td>\n",
       "      <td>Nice breakfast handy for Victoria train stati...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id  \\\n",
       "0  00003c6036f30f590c0ac435efb8739b   \n",
       "1  00004d18f186bf2489590dc415876f73   \n",
       "2  0000cf900cbb8667fad33a717e9b1cf4   \n",
       "3  0000df16edf19e7ad9dd8c5cd6f6925e   \n",
       "4  00025e1aa3ac32edb496db49e76bbd00   \n",
       "\n",
       "                                            negative  \\\n",
       "0         There were issues with the wifi connection   \n",
       "1                                     TV not working   \n",
       "2                                       More pillows   \n",
       "3                                      Very business   \n",
       "4   Rooms could do with a bit of a refurbishment ...   \n",
       "\n",
       "                                            positive  score  \n",
       "0                                        No Positive    7.1  \n",
       "1                                        No Positive    7.5  \n",
       "2        Beautiful room Great location Lovely staff    10.0  \n",
       "3                                           Location    5.4  \n",
       "4   Nice breakfast handy for Victoria train stati...    6.7  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "df = pd.read_csv(PATH_TO_TRAIN_DATA)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ghaiGdiFk_t3"
   },
   "outputs": [],
   "source": [
    "df = df.loc[(df['negative'] != 'nothing') | (df['positive'] != 'no positive')]\n",
    "df = df.loc[(df['negative'] != 'no negative') |  (df['positive'] != 'no positive')]\n",
    "df = df.loc[(df['negative'] != 'no negative') |  (df['positive'] != 'nothing')]\n",
    "df = df.loc[(df['negative'] != 'nothing') |  (df['positive'] != 'nothing')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnAZmFZWFqUY",
    "outputId": "6c4735ec-321c-4dd7-83ac-a29d88899c60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.19.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (4.54.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (0.1.94)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.7.1+cu110)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (0.0.43)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.16.42)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2020.11.13)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch_transformers) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->pytorch_transformers) (0.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.0.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.42 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (1.19.42)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->pytorch_transformers) (2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (1.26.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (4.0.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.42->boto3->pytorch_transformers) (2.8.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zdVz-qOq-13v"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from pytorch_transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from pytorch_transformers import RobertaConfig\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kSWYx34w-yig"
   },
   "outputs": [],
   "source": [
    "df['final_preprocessing'] = df['negative'] + '. ' + df['positive'] #сделаем столбец где будем хранить негативные и позитивные отзывы вместе\n",
    "\n",
    "set_score = list(set(df.score.tolist()))\n",
    "dict_score = {set_score[item]:item for item in range(len(set_score))}\n",
    "def change(score):\n",
    "    return(dict_score[score['score']])\n",
    "  \n",
    "df['score_class'] = df.apply(change, axis=1)\n",
    "\n",
    "df_train, df_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "buw5eF3ZA6kv"
   },
   "outputs": [],
   "source": [
    "sentences_train = [sentence for sentence in df_train['final_preprocessing']]\n",
    "labels_train = [item for item in df_train['score_class'].tolist()]\n",
    "\n",
    "sentences_test = [sentence for sentence in df_test['final_preprocessing']]\n",
    "labels_test = [item for item in df_test['score_class'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fr4FTTRC-_UI",
    "outputId": "50e62193-ffe8-4828-f77b-c233e6e161b9"
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base',add_special_tokens=True)# будем использовать базовые Берт, где слова имеют нижний регистр\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZWxRLI7ETfp",
    "outputId": "887a450d-aa70-4f03-83ed-b4cb4085eed8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 250\n",
    "train_input = [tokenizer.encode(x,add_special_tokens=True) for x in sentences_train]\n",
    "\n",
    "train_pos_pad = pad_sequence([torch.as_tensor(seq[:MAX_LEN]) for seq in train_input], \n",
    "                           batch_first=True)\n",
    "\n",
    "train_masks = [[float(i>0) for i in seq] for seq in train_pos_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dg-PeTsHETdj",
    "outputId": "037f0ec5-e360-4ac8-9280-10e1a5bec7f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "test_input = [tokenizer.encode(x, add_special_tokens=True) for x in sentences_test]\n",
    "test_pos_pad = pad_sequence([torch.as_tensor(seq[:MAX_LEN]) for seq in test_input], \n",
    "                           batch_first=True)\n",
    "\n",
    "validation_masks = [[float(i>0) for i in seq] for seq in test_pos_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZIh8iJPkETbC",
    "outputId": "fe324d3a-d134-4465-a6e0-6ca2f2bce6a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_inputs = torch.tensor(train_pos_pad)\n",
    "train_labels = torch.tensor(labels_train)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "\n",
    "\n",
    "validation_inputs = torch.tensor(test_pos_pad)\n",
    "validation_labels = torch.tensor(labels_test)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vnygQBcNETYp"
   },
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, shuffle=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9rO6GPEkO00R",
    "outputId": "9635a8bb-021b-4442-b36d-0bde741f2e5e"
   },
   "outputs": [],
   "source": [
    "num_labels = len(df_train.score.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7QFtJuURETWQ",
    "outputId": "040ef753-c13b-4bf0-d673-47de2b8d4e0f"
   },
   "outputs": [],
   "source": [
    "config = RobertaConfig.from_pretrained(\"roberta-base\", output_hidden_states=True, num_labels=num_labels)\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MZSJnN8ZElC6"
   },
   "outputs": [],
   "source": [
    "# функция перевода метки класса в score\n",
    "dict_score_class = {item:set_score[item] for item in range(len(set_score))} #set_score = list(set(df.score.tolist())) (Напоминание)\n",
    "def mae(pred, label):\n",
    "    pred =  [dict_score_class[item] for item in pred]\n",
    "    label = [dict_score_class[item] for item in label]\n",
    "    return mean_absolute_error(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, criterion, optimizer, device=\"cuda:0\"):\n",
    "    model.to(device).train()\n",
    "    with tqdm(total=len(train_dataloader)) as pbar:\n",
    "        for batch in train_dataloader:\n",
    "            # добавляем батч для вычисления на GPU\n",
    "            # Распаковываем данные из dataloader\n",
    "            input_ids, input_mask, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(input_ids, token_type_ids=None, attention_mask=input_mask)[0]\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            \n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(output.detach(), 1)\n",
    "            accuracy_mae = mae(predicted.cpu().numpy(), labels.cpu().numpy())\n",
    "            pbar.set_description('Loss: {:.4f}; Accuracy_MAE: {:.4f}'.format(loss.item(), accuracy_mae))    \n",
    "            pbar.update(1)\n",
    "            \n",
    "def predict(model, val_dataloader, criterion, device=\"cuda:0\"):\n",
    "    model.to(device).eval()\n",
    "    losses = []\n",
    "    predicted_classes = []\n",
    "    true_classes = []\n",
    "    with tqdm(total=len(val_dataloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                \n",
    "                input_ids, input_mask, labels = batch\n",
    "                input_ids = input_ids.to(device)\n",
    "                input_mask = input_mask.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                \n",
    "                output = model.forward(input_ids, token_type_ids=None, attention_mask=input_mask)[0]\n",
    "                _, predicted = torch.max(output, 1)\n",
    "            \n",
    "                loss = criterion(output, labels)\n",
    "                losses.append(loss.item())\n",
    "                _, predicted = torch.max(output.detach(), 1)\n",
    "                predicted_classes.append(predicted)\n",
    "                true_classes.append(labels)\n",
    "                \n",
    "                \n",
    "                accuracy_mae = mae(predicted.cpu().numpy(), labels.cpu().numpy())\n",
    "                pbar.set_description('Loss: {:.4f}; Accuracy_MAE: {:.4f}'.format(loss.item(), accuracy_mae))    \n",
    "                pbar.update(1)\n",
    "                \n",
    "    predicted_classes = torch.cat(predicted_classes).detach().to('cpu').numpy()\n",
    "    true_classes = torch.cat(true_classes).detach().to('cpu').numpy()\n",
    "    return losses, predicted_classes, true_classes\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", n_epochs=10, scheduler=None):\n",
    "    model.to(device)\n",
    "    lrs = []\n",
    "    for epoch in range(n_epochs):\n",
    "        print('Learning rate: ', optimizer.param_groups[0]['lr'])\n",
    "        print('Epoc:', epoch)\n",
    "        train_one_epoch(model, train_dataloader, criterion, optimizer)\n",
    "        print('Validation')\n",
    "        losses, predicted_classes, true_classes = predict(model, val_dataloader, criterion)\n",
    "        print('Accuracy_MAE: ', mae(true_classes, predicted_classes))\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "        scheduler.step()\n",
    "    plt.plot(lrs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "learning_rate = 1e-05\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.1,step_size_up=5,mode=\"triangular2\")\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=0.0001, last_epoch=-1)\n",
    "n_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-05\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2344 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1e-05\n",
      "Epoc: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1218; Accuracy_MAE: 0.8333%: 100%|██████████| 2344/2344 [11:40<00:00,  3.35it/s]\n",
      "Loss: 2.3241; Accuracy_MAE: 0.9328:   0%|          | 1/391 [00:00<01:10,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1552; Accuracy_MAE: 0.7775: 100%|██████████| 391/391 [01:11<00:00,  5.50it/s]\n",
      "  0%|          | 0/2344 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_MAE:  0.759064\n",
      "Learning rate:  1e-05\n",
      "Epoc: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9606; Accuracy_MAE: 0.7083%: 100%|██████████| 2344/2344 [11:41<00:00,  3.34it/s]\n",
      "Loss: 2.3892; Accuracy_MAE: 0.9641:   0%|          | 1/391 [00:00<01:10,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2105; Accuracy_MAE: 0.8425: 100%|██████████| 391/391 [01:11<00:00,  5.46it/s]\n",
      "  0%|          | 0/2344 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_MAE:  0.7765079999999999\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoc: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8149; Accuracy_MAE: 0.6708%: 100%|██████████| 2344/2344 [11:42<00:00,  3.34it/s]\n",
      "Loss: 2.3153; Accuracy_MAE: 0.8641:   0%|          | 1/391 [00:00<01:10,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2494; Accuracy_MAE: 0.9050: 100%|██████████| 391/391 [01:11<00:00,  5.45it/s]\n",
      "  0%|          | 0/2344 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_MAE:  0.73834\n",
      "Learning rate:  1.0000000000000002e-06\n",
      "Epoc: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7368; Accuracy_MAE: 0.4344%:   1%|          | 15/2344 [00:04<12:16,  3.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5e245df729bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-e52bcc9d4d1b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Learning rate: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-e52bcc9d4d1b>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_dataloader, validation_dataloader, criterion, optimizer, device, n_epochs, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST_DATA = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00026f564b258ad5159aab07c357c4ca</td>\n",
       "      <td>Other than the location everything else was h...</td>\n",
       "      <td>Just the location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000278c73da08f4fcb857fcfe4ac6417</td>\n",
       "      <td>No UK TV but this was a minor point as we wer...</td>\n",
       "      <td>Great location very comfortable clean breakfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000404f843e756fe3b2a477dbefa5bd4</td>\n",
       "      <td>A tiny noisy room VERY deceptively photographed</td>\n",
       "      <td>The breakfast booked the preceding night but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000a66d32bcf305148d789ac156dd512</td>\n",
       "      <td>Noisy various electrical devices kicking in r...</td>\n",
       "      <td>Great location Nice bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000bf1d8c5110701f459ffbedbf0d546</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>Great location and friendly staff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          review_id  \\\n",
       "0  00026f564b258ad5159aab07c357c4ca   \n",
       "1  000278c73da08f4fcb857fcfe4ac6417   \n",
       "2  000404f843e756fe3b2a477dbefa5bd4   \n",
       "3  000a66d32bcf305148d789ac156dd512   \n",
       "4  000bf1d8c5110701f459ffbedbf0d546   \n",
       "\n",
       "                                            negative  \\\n",
       "0   Other than the location everything else was h...   \n",
       "1   No UK TV but this was a minor point as we wer...   \n",
       "2   A tiny noisy room VERY deceptively photographed    \n",
       "3   Noisy various electrical devices kicking in r...   \n",
       "4                                        No Negative   \n",
       "\n",
       "                                            positive  \n",
       "0                                 Just the location   \n",
       "1   Great location very comfortable clean breakfa...  \n",
       "2   The breakfast booked the preceding night but ...  \n",
       "3                       Great location Nice bathroom  \n",
       "4                  Great location and friendly staff  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(PATH_TO_TEST_DATA)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['final_preprocessing'] = df_test['negative'] + '. ' + df_test['positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_test = [sentence for sentence in df_test['final_preprocessing']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 250\n",
    "test_input = [tokenizer.encode(x,add_special_tokens=True) for x in sentences_test]\n",
    "\n",
    "test_pos_pad = pad_sequence([torch.as_tensor(seq[:MAX_LEN]) for seq in test_input], \n",
    "                           batch_first=True)\n",
    "\n",
    "test_masks = [[float(i>0) for i in seq] for seq in test_pos_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "validation_inputs = torch.tensor(test_pos_pad)\n",
    "validation_masks = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = TensorDataset(validation_inputs, validation_masks)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, val_dataloader, device=\"cuda:0\"):\n",
    "    model.to(device).eval()\n",
    "    losses = []\n",
    "    predicted_classes = []\n",
    "    true_classes = []\n",
    "    valid_preds, valid_labels = [], []\n",
    "    with tqdm(total=len(val_dataloader)) as pbar:\n",
    "        with torch.no_grad():\n",
    "            for step, batch in enumerate(val_dataloader):\n",
    "                # добавляем батч для вычисления на GPU\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "                # Распаковываем данные из dataloader\n",
    "                input_ids, input_mask = batch\n",
    "\n",
    "                logits = model(input_ids, token_type_ids=None, attention_mask=input_mask)\n",
    "\n",
    "                logits = logits[0].detach().cpu().numpy()\n",
    "\n",
    "\n",
    "                batch_preds = np.argmax(logits, axis=1)\n",
    "    \n",
    "                valid_preds.extend(batch_preds)\n",
    "\n",
    "                pbar.set_description('Step: {:.4f}'.format(step))\n",
    "                pbar.update(1)\n",
    "\n",
    "    return valid_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step: 624.0000: 100%|██████████| 625/625 [00:58<00:00, 10.72it/s]\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = predict(model, validation_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred =  [dict_score_class[item] for item in predicted_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['score'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[['review_id','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('predict.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На Kaggle профиль alexserg98, MAE:0.74883"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dop_dz_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
